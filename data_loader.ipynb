{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import multiprocessing as mp\n",
    "\n",
    "client = MongoClient(\"localhost\", 27017, client= False)\n",
    "db = client['usgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_datetime(d, t, tz):\n",
    "    dt_obj = dt.datetime(year   = int(d[0:4]), \n",
    "                         month  = int(d[4:6]), \n",
    "                         day    = int(d[6:8]), \n",
    "                         hour   = int(t[0:2]), \n",
    "                         minute = int(t[2:4]), \n",
    "                         second = int(t[4:6]))\n",
    "    return int(time.mktime(dt_obj.utctimetuple()) + tz*3600)\n",
    "\n",
    "\n",
    "def load_sites_info(db, data_folder, sites_info_file, overwrite = True, verbosity = 100):\n",
    "    filelist = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n",
    "    df = pd.read_csv(sites_info_file)\n",
    "\n",
    "    collection = db['sites']\n",
    "    if overwrite:\n",
    "        collection.delete_many({})\n",
    "\n",
    "    for i, f in enumerate(filelist):\n",
    "        tags = f.split('.')    \n",
    "        if i % verbosity == 0:\n",
    "            print(i, f)\n",
    "            \n",
    "        if tags[3] == 'web' or tags[3] == 'comp':\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(data_folder, f)) as file:\n",
    "            while file.readline()[0] == '#':\n",
    "                pass\n",
    "            file.readline()    \n",
    "            line = file.readline()\n",
    "            if len(line) > 0:\n",
    "                prec = int(line.split('\\t')[4])\n",
    "            else:\n",
    "                prec = -1\n",
    "\n",
    "        site_no = int(tags[1])\n",
    "        site_info = df.loc[df['SITE_NO'] == site_no].iloc[0]\n",
    "        site = {\n",
    "            \"site_no\": site_no,\n",
    "            \"description\": site_info['STATION_NM'],\n",
    "            \"lat\": site_info['DEC_LAT_VA'],\n",
    "            \"lon\": site_info['DEC_LONG_V'],\n",
    "            \"state\": site_info['STATE_NM'],\n",
    "            \"district\": site_info['DISTRICT_N'],\n",
    "            \"drain_area\": site_info['DRAIN_AREA'],\n",
    "            \"status\": site_info['STATUS_15'],\n",
    "            \"precision\": prec,\n",
    "        }\n",
    "        collection.insert_one(site)  \n",
    "        \n",
    "    return collection\n",
    "\n",
    "\n",
    "def load_data_worker(measured, computed, filelist, data_folder):\n",
    "    tz_codes = {'AKDT': -8, 'AKST': -9, 'AST' : -4, 'CDT' : -6, 'CST' : -5, 'EDT' : -4, 'EST' : -5, 'GST' : -2, \n",
    "                'HST' : -10, 'MDT' : -6, 'MST' : -7, 'PDT' : -7, 'PST' : -8}    \n",
    "    for i, f in enumerate(filelist):\n",
    "        tags = f.split('.')            \n",
    "        if tags[3] != 'meas' and tags[3] != 'comp':\n",
    "            continue\n",
    "        site_no = int(tags[1])\n",
    "        \n",
    "        utc = list()\n",
    "        gh = list()\n",
    "        with open(os.path.join(data_folder, f)) as file:\n",
    "            while file.readline()[0] == '#':\n",
    "                pass\n",
    "            file.readline()        \n",
    "            for line in file.readlines():\n",
    "                if len(line) < 1:\n",
    "                    continue\n",
    "                val = line.split('\\t')\n",
    "                ts = parse_datetime(val[0], val[1], tz_codes[val[2]])\n",
    "                utc.append(ts)\n",
    "                gh.append(float(val[3]))        \n",
    "        if len(utc) < 2 or len(gh) < 2:\n",
    "            continue            \n",
    "        measurement = {\"site_no\": site_no, \"utc\": utc, \"gh\": gh} \n",
    "        if tags[3] == \"meas\":\n",
    "            measured.insert_one(measurement)\n",
    "        else:\n",
    "            computed.insert_one(measurement)        \n",
    "    return\n",
    "\n",
    "        \n",
    "def load_measurement_data(db, data_folder, n_jobs = 4, overwrite = True, verbosity = 100):\n",
    "    filelist = [f for f in os.listdir(data_folder) if os.path.isfile(os.path.join(data_folder, f))]\n",
    "        \n",
    "    if overwrite:\n",
    "        db['measured'].delete_many({})\n",
    "        db['computed'].delete_many({})\n",
    "        \n",
    "    n = len(filelist)\n",
    "    k = n // n_jobs\n",
    "\n",
    "    jobs = list()\n",
    "    for i in range(n_jobs):\n",
    "        chunk = filelist[i*k:min((i+1)*k, n)]\n",
    "        p = mp.Process(target = load_data_worker, \n",
    "                       args   = (db['measured'], db['computed'], chunk, data_folder))\n",
    "        jobs.append(p)\n",
    "        p.start()   \n",
    "    \n",
    "    for job in jobs:\n",
    "        job.join()\n",
    "    \n",
    "    return db['meas'], db['comp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sites info...\n",
      "...done.\n",
      "Loading measurments data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmtlevin/anaconda/lib/python3.5/site-packages/pymongo/topology.py:143: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#using-pymongo-with-multiprocessing>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/dmtlevin/anaconda/lib/python3.5/site-packages/pymongo/topology.py:143: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#using-pymongo-with-multiprocessing>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/dmtlevin/anaconda/lib/python3.5/site-packages/pymongo/topology.py:143: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#using-pymongo-with-multiprocessing>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/dmtlevin/anaconda/lib/python3.5/site-packages/pymongo/topology.py:143: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#using-pymongo-with-multiprocessing>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done.\n",
      "Creating indexes...\n",
      "...done.\n"
     ]
    }
   ],
   "source": [
    "print('Loading sites info...')\n",
    "#sites = load_sites_info(db, data_folder = 'data/', sites_info_file = 'sites.csv', overwrite = True, verbosity = 100)\n",
    "print('...done.')\n",
    "\n",
    "print('Loading measurments data...')\n",
    "measured, verified = load_measurement_data(db, data_folder = 'data/', overwrite = True, verbosity = 5)\n",
    "print('...done.')\n",
    "\n",
    "print('Creating indexes...')\n",
    "#sites.create_index('site_no')\n",
    "measured.create_index('site_no')\n",
    "verified.create_index('site_no')\n",
    "print('...done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['measured'].count()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
